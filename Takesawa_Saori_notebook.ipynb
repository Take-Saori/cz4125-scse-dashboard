{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e89850e-8575-45b5-9588-d80ce4446b13",
   "metadata": {},
   "source": [
    "# 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac8da2f0-f2bb-41d8-aa9c-8a26c2399283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# collections.Callable has been moved to collections.abc.Callable in python 3.10+.\n",
    "# Hence, the below lines are added.\n",
    "# Without it, there will be an error: AttributeError: module 'collections' has no attribute 'Callable'\n",
    "import collections\n",
    "collections.Callable = collections.abc.Callable\n",
    "from collections import Counter\n",
    "\n",
    "import bs4 # imported to compare if certain bs4 object are a certain bs4 type\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import math\n",
    "import re\n",
    "from scholarly import scholarly\n",
    "from pprint import pprint\n",
    "import urllib\n",
    "import urllib.parse\n",
    "from urllib.parse import urljoin, urlparse, parse_qs\n",
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "import json\n",
    "from thefuzz import process\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfaa927-dbf0-467f-901a-2e87d34e6bbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9795e54-f38e-42ae-861c-5562690c1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_result(query_url):\n",
    "    \"\"\"\n",
    "    Return API result by using query_url.\n",
    "\n",
    "    Input:\n",
    "    - query_url (string): URL to query to API.\n",
    "\n",
    "    Output:\n",
    "    - result (Dict): Dictionary of results from the API.\n",
    "                     If error occurs, return the error details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = urlopen(query_url)\n",
    "        result = json.loads(response.read().decode('utf-8'))\n",
    "        return result\n",
    "    except HTTPError as e:\n",
    "        # Handle any HTTP error by returning a custom error message\n",
    "        return {\"error\": f\"HTTP error {e.code}: {e.reason}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ea2287-43f0-4e10-85c4-a9ff1f2612b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_index(find_string, string_list):\n",
    "    \"\"\"\n",
    "    Return the index of the string (in string_list), that is the most similar with find_string.\n",
    "\n",
    "    Input:\n",
    "    - find_string (string): String to find in string_list.\n",
    "    - string_list (List(string)): List of strings.\n",
    "\n",
    "    Output:\n",
    "    - similar_index (int): Index of the string (in string_list) that is most similar to find_string.\n",
    "                           If there is no string that is at least 70% similar to find_string,\n",
    "                           return None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the name that is most similar\n",
    "    similar_name, _ = process.extractOne(find_string, string_list)\n",
    "    similar_name_index = string_list.index(similar_name)\n",
    "\n",
    "    return similar_name_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bec00e4-16e8-4699-996f-eb5b0f9b7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_words(input_string, at_least_num):\n",
    "    \"\"\"\n",
    "    Return True if the string contains at least at_least_num words.\n",
    "    Return False otherwise.\n",
    "\n",
    "    Input:\n",
    "    - input_string (string): String to count the no. of words.\n",
    "    - at_least_num (int): Number of words the string should at least contain,\n",
    "                    to return True.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split the string into words using spaces as the delimiter\n",
    "    words = input_string.split()\n",
    "    \n",
    "    # Check if the no .of words is at least at_least_num\n",
    "    if len(words) >= at_least_num:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e1db0e-06fe-4b26-9e98-935ed2551a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_list_with_value(list_of_lists, target_value):\n",
    "    \"\"\"\n",
    "    Return index of a list that contains the target value, from a list of lists.\n",
    "\n",
    "    Input:\n",
    "    - list_of_lists ( List( List(string) ) ): List of lists.\n",
    "    - target_value (string): String to search for in the list of lists.\n",
    "\n",
    "    Output:\n",
    "    - index (int): Index of list that contains target_value.\n",
    "                   If no list contains the target_value, return -1.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    for index, sub_list in enumerate(list_of_lists):\n",
    "        if target_value in sub_list:\n",
    "            return index  # Return the index of the list containing the value\n",
    "    return -1  # Return -1 if the value is not found in any list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ad5ee-9a14-4fad-a3c4-2258f31a35fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Functions for DR-NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9505678f-67f3-414e-9a93-0a55246db56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_research_interest_from_drNTU(drNTU_link):\n",
    "    \"\"\"\n",
    "    Return the list of tags of the researcher in their DR-NTU page.\n",
    "\n",
    "    Input:\n",
    "    - drNTU_link (string): DR-NTU profile URL of a SCSE faculty.\n",
    "\n",
    "    Output:\n",
    "    - tag_list (List(string)) : List of research interest found on DR-NTU profile page of that faculty.\n",
    "                                Return nan if not avilable.\n",
    "    \"\"\"\n",
    "    soup_source = requests.get(drNTU_link).text\n",
    "    soup = BeautifulSoup(soup_source,'lxml')\n",
    "\n",
    "    try:\n",
    "        tag_list = []\n",
    "    \n",
    "        for tag in soup.find('div', id='taxonomyDiv', class_='dynaFieldValue').find_all('span', class_='rkeyword'):\n",
    "            tag_name = tag.text.strip()\n",
    "            if not tag_name == 'Computer Science and Engineering':\n",
    "                tag_list.append(tag_name)\n",
    "\n",
    "        # If no tags available\n",
    "        if len(tag_list) == 0:\n",
    "            return float('nan')\n",
    "        \n",
    "        return tag_list\n",
    "        \n",
    "    except:\n",
    "        return float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f885951-b5f0-4e46-a1e6-747fcf219848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Individual Assignment 1\n",
    "def get_cleaned_pub_list(unprocessed_pub_list):\n",
    "    \"\"\"\n",
    "    Return list of cleaned publication citation from the unprocessed_pub_list retrieved\n",
    "    from the DR-NTU profile publication tab.\n",
    "\n",
    "    Input:\n",
    "        - unprocessed_pub_list (list): List of publication details extracted by BeautifulSoup.\n",
    "                                       It also contains elements that are tags, without any text.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize variables\n",
    "    cleaned_pub_list = []\n",
    "    current_subset = []\n",
    "    \n",
    "    # To keep track of the number of consecutive <br/> elements\n",
    "    # Because each publication can be splitted by 2 consecutive <br/> elements\n",
    "    br_count = 0\n",
    "    \n",
    "    # Iterate through the unprocessed_pub_list\n",
    "    for item in unprocessed_pub_list:\n",
    "        \n",
    "        # Check if the item is a string or a BeautifulSoup object\n",
    "        if isinstance(item, str):\n",
    "            # If it is a string, add it to the current_subset\n",
    "            current_subset.append(item)\n",
    "            \n",
    "        elif str(item) != '<br/>':\n",
    "            # If it is a BeautifulSoup object and not <br/>, convert it to a string and add it to the current_subset\n",
    "            current_subset.append(str(item))\n",
    "    \n",
    "        # Check if the current item is a <br/>\n",
    "        if str(item) == '<br/>':\n",
    "            br_count += 1\n",
    "            if br_count == 2:\n",
    "                # If two consecutive <br/> tags are found,\n",
    "                # concatenate the current subset and reset it\n",
    "                cleaned_pub_list.append(''.join(current_subset))\n",
    "                \n",
    "                # Empty current_subset to store the next subset\n",
    "                current_subset = []\n",
    "                \n",
    "            elif br_count > 2:\n",
    "                # If more than 2 consecutive <br/> tags are found, reset the count\n",
    "                br_count = 1\n",
    "    \n",
    "    # Append the last subset if there are remaining elements\n",
    "    if current_subset:\n",
    "        cleaned_pub_list.append(''.join(current_subset))\n",
    "\n",
    "    # Remove the subsets that are not publication citations\n",
    "    remove_list = ['<br/>', 'Highly Cited:', 'Click', 'Recent Publication:']\n",
    "    for remove_word in remove_list:\n",
    "        cleaned_pub_list[:] = [subset for subset in cleaned_pub_list if remove_word not in subset]\n",
    "\n",
    "    # Remove element that is a empty string\n",
    "    cleaned_pub_list[:] = [subset for subset in cleaned_pub_list if not subset == '']\n",
    "\n",
    "    # Remove the tags in the citations\n",
    "    replace_list = ['<b>', '</b>', '<i>', '</i>']\n",
    "    for replace_word in replace_list:\n",
    "        cleaned_pub_list[:] = [subset.replace(replace_word, '') for subset in cleaned_pub_list]\n",
    "    \n",
    "    return cleaned_pub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6e85c6-39b9-4c2b-acf0-3d1ea6e06151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unprocessed_pub_list(drNTU_link):\n",
    "    \"\"\"\n",
    "    Return publication details from DR-NTU faculty's profile in publication tab.\n",
    "\n",
    "    Input:\n",
    "    -  drNTU_link (string): DR-NTU profile link (in publication tab) of a SCSE faculty.\n",
    "\n",
    "    Output:\n",
    "    - unprocessed_pub_list (list): List of publication details extracted by BeautifulSoup.\n",
    "                                       It also contains elements that are tags, without any text.\n",
    "    \"\"\"\n",
    "\n",
    "    # print(drNTU_link+'/selectedPublications.html')\n",
    "    soup_source = requests.get(drNTU_link+'/selectedPublications.html').text\n",
    "    soup = BeautifulSoup(soup_source,'lxml')\n",
    "\n",
    "    # If \"Articles (Journal)\" tab does not exist for this faculty,\n",
    "    # return an empty list\n",
    "    if not soup.find('div', id=\"facultyjournalDiv\"):\n",
    "        return []\n",
    "    \n",
    "    # Get publication list from the profile page, but unprocessed\n",
    "    unprocessed_pub_list = soup.find('div', id=\"facultyjournalDiv\").contents[1].contents\n",
    "\n",
    "    return unprocessed_pub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d615877-96ef-4107-ae12-ea85a8483f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doi_list_from_drNTU(drNTU_link):\n",
    "    \"\"\"\n",
    "    Return the list of DOI of all publications written by the researcher, in their DR-NTU page.\n",
    "\n",
    "    Input:\n",
    "    - drNTU_link (string): DR-NTU profile link (in publication tab) of a SCSE faculty.\n",
    "\n",
    "    Output:\n",
    "    - doi_list (List(string)) : List of DOI found on DR-NTU publication page of that faculty.\n",
    "    \"\"\"\n",
    "\n",
    "    doi_list = []\n",
    "    \n",
    "    # Get publication list from the profile page, but unprocessed\n",
    "    unprocessed_pub_list = get_unprocessed_pub_list(drNTU_link)\n",
    "\n",
    "    # Get the processed version of the publication \n",
    "    cleaned_pub_list = get_cleaned_pub_list(unprocessed_pub_list)\n",
    "\n",
    "    # Regex to extract DOI\n",
    "    doi_pattern = r'doi:\\s+(\\S+)'\n",
    "\n",
    "    for pub in cleaned_pub_list:\n",
    "        match = re.search(doi_pattern, pub)\n",
    "\n",
    "        if match:\n",
    "            doi_list.append(match.group(1))\n",
    "\n",
    "    return doi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ee2c6fb-87aa-4416-a22c-2ff602b9b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified code from Assignment 1\n",
    "def get_pub_list_from_article(drNTU_link):\n",
    "    \"\"\"\n",
    "    Return list of all publication with title only, from the \"Articles (Journal)\" tab if it exist\n",
    "\n",
    "    <pub_1_title> will not be appended if <pub_1_title> was not correctly extracted by regex.\n",
    "\n",
    "    Input:\n",
    "    - dr_ntu_pub_link (string): DR-NTU profile link (in publication tab)\n",
    "\n",
    "    Output:\n",
    "    - pub_title_list (List(string)): List of publication extracted from faculty's profile in publication tab.\n",
    "    \"\"\"\n",
    "\n",
    "    # List to store list of publication title and year.\n",
    "    pub_title_list = []\n",
    "    \n",
    "    # Get publication list from the profile page, but unprocessed\n",
    "    unprocessed_pub_list = get_unprocessed_pub_list(drNTU_link)\n",
    "\n",
    "    # Get the processed version of the publication \n",
    "    cleaned_pub_list = get_cleaned_pub_list(unprocessed_pub_list)\n",
    "    \n",
    "    # Extract title and year from all the publications\n",
    "    for pub in cleaned_pub_list:\n",
    "        one_pub_title = get_one_pub_title(pub)\n",
    "        \n",
    "        # If title was retrieved\n",
    "        if one_pub_title:\n",
    "            # If the title have at least 3 words,\n",
    "            # append to the list\n",
    "            if have_words(one_pub_title, 3):\n",
    "                pub_title_list.append(one_pub_title)\n",
    "\n",
    "    return pub_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "817581d1-abd5-4b3f-9053-f54806623517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified code from Assignment 1\n",
    "def get_one_pub_title(pub_citation):\n",
    "    \"\"\"\n",
    "    Return publication title for one publication citation.\n",
    "    The citation will not be a full citation. \n",
    "    Return None if title could not be retrieved.\n",
    "\n",
    "    Input:\n",
    "    - pub_citation (string): Citation of a paper retrieved from publication tab\n",
    "                              in DR-NTU profile page of a SCSE faculty.\n",
    "\n",
    "    Output:\n",
    "    - pub_title (string): Title of the publication retrieved from the citation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # If there is double inverted commas in the citation, that is the title.\n",
    "    # So get the title between the double inverted commas\n",
    "    if '\"' in pub_citation or '“' in pub_citation or '”' in pub_citation:\n",
    "        # Replace the other variation of double inverted commas\n",
    "        # to the default ones\n",
    "        pub_citation = pub_citation.replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "\n",
    "        # Extract the title and year (if exist)\n",
    "        pub_title = re.findall(r'\"(.*?)\"', pub_citation)[0]\n",
    "        \n",
    "        return pub_title\n",
    "\n",
    "    # For papers that do not have double inverted commas:\n",
    "    pattern = r'(\\d{4}),*\\s*\\w*[),.]+\\s*(.*?)[,.]'\n",
    "    matches = re.findall(pattern, pub_citation)\n",
    "\n",
    "    # If no match found\n",
    "    if len(matches) == 0: \n",
    "        return None\n",
    "\n",
    "    # If match found\n",
    "    pub_title = matches[0][1]\n",
    "\n",
    "    return pub_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a82268-72a9-43b1-8e79-a08d9e0f9ba6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. Functions for OpenAlex API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef1bf1f-0c88-4a53-a0a8-7008ea21beff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_info_from_OpenAlexAPI(author_name, keyword, mode):\n",
    "    \"\"\"\n",
    "    Return the dictionary of details of a specified author of the publication with specified doi.\n",
    "    \n",
    "    Input:\n",
    "    - author_name (string): Name of the author retrieved from DR-NTU.\n",
    "                            It will not be used when mode='orcid', as only the keyword is needed in that mode.\n",
    "    - keyword (string): Term related to the author, which is used to search the author's details.\n",
    "                        When mode='institution', keyword will not be used as the instituion ID (of NTU),\n",
    "                        which is needed for this mode, will be defined in this function. Hence, it will\n",
    "                        be usually left as an empty string for that mode.\n",
    "    - mode (string): To indicate search method of author.\n",
    "                     - if 'api_id', search author based on author's OpenAlex id.\n",
    "                     - if 'doi', search author based on name and Digital Object Identifier (DOI) of a publication,\n",
    "                       with author_name as one of the authors.\n",
    "                     - if 'orcid', search author based on their ORCID profile link.\n",
    "                     - if 'pub', search author based on name and publication title written by the author.\n",
    "                     - if 'institution', search author based on last institution, name and x_concept.\n",
    "                     - if 'name', search author based on name and x_concept.\n",
    "\n",
    "    Output:\n",
    "    - author_info (dict): Dictionary containing the details of the author by OpenAlex API.\n",
    "    \"\"\"\n",
    "    \n",
    "    if mode == 'api_id':\n",
    "        query_url = 'https://api.openalex.org/authors/' + keyword\n",
    "        author_info = get_api_result(query_url)            \n",
    "        return author_info\n",
    "        \n",
    "    elif mode == 'doi':\n",
    "        # API Query to search for pub with the specified doi\n",
    "        query_url = \"https://api.openalex.org/works/https://doi.org/\" + keyword\n",
    "        # print(query_url)\n",
    "        result = get_api_result(query_url)\n",
    "\n",
    "        # If API gave error\n",
    "        if 'error' in result:\n",
    "            return result\n",
    "\n",
    "        # If no authors written\n",
    "        if len(result['authorships']) == 0:\n",
    "            return []\n",
    "    \n",
    "        authors_list = []\n",
    "    \n",
    "        # Get all authors' name\n",
    "        for author in result['authorships']:\n",
    "            authors_list.append(author['author']['display_name'])\n",
    "    \n",
    "        # Compare the names with author_name and get the index with the highest similarity\n",
    "        similar_index = get_most_similar_index(author_name, authors_list)\n",
    "        author_info = result['authorships'][similar_index]\n",
    "\n",
    "        return author_info\n",
    "\n",
    "    elif mode == 'orcid':\n",
    "        # Get details by ORCID id\n",
    "        query_url = \"https://api.openalex.org/authors/\" + keyword\n",
    "        # print(query_url)\n",
    "        author_info = get_api_result(query_url)            \n",
    "        return author_info\n",
    "\n",
    "    elif mode == 'pub':\n",
    "        # Get details by searching with publication title\n",
    "        \n",
    "        # Convert the name for query url\n",
    "        query_converted_pub = urllib.parse.quote_plus(keyword)\n",
    "        query_url = \"https://api.openalex.org/works?search=\" + query_converted_pub\n",
    "        # print(query_url)\n",
    "        result = get_api_result(query_url) \n",
    "\n",
    "        # If API gave error\n",
    "        if 'error' in result:\n",
    "            return result\n",
    "\n",
    "        # If no results or no authors written\n",
    "        if len(result['results']) == 0 or len(result['results'][0]['authorships']) == 0:\n",
    "            return []\n",
    "\n",
    "        authors_list = []\n",
    "    \n",
    "        # Get all authors' name from the first candinate publication only\n",
    "        for author in result['results'][0]['authorships']:\n",
    "            authors_list.append(author['author']['display_name'])\n",
    "    \n",
    "        # Compare the names with author_name and get the index with the highest similarity\n",
    "        similar_index = get_most_similar_index(author_name, authors_list)\n",
    "        author_info = result['results'][0]['authorships'][similar_index]\n",
    "\n",
    "        return author_info\n",
    "\n",
    "    elif mode == 'institution':\n",
    "        # Get details by last institution\n",
    "\n",
    "        # Convert the name for query url\n",
    "        query_converted_name = urllib.parse.quote_plus(author_name)\n",
    "        \n",
    "        query_url = 'https://api.openalex.org/authors?search=' + query_converted_name \\\n",
    "                    + '&filter=last_known_institution.id:I172675005,' \\\n",
    "                    + 'x_concepts.id:C41008148&sort=relevance_score:desc'\n",
    "        result = get_api_result(query_url)\n",
    "        # print(query_url)\n",
    "\n",
    "        # If API gave error\n",
    "        if 'error' in result:\n",
    "            return result\n",
    "\n",
    "        # If no results\n",
    "        if len(result['results']) == 0:\n",
    "            return []\n",
    "\n",
    "        for candinate in result['results']:\n",
    "            # Check if the author is relevant to 'Computer Science'\n",
    "            for tag in candinate['x_concepts']:\n",
    "                if tag['display_name'] == 'Computer science':\n",
    "                    if tag['score'] > 70:\n",
    "                        author_info = candinate\n",
    "                        return author_info\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "        # If no possible candinate\n",
    "        return []\n",
    "\n",
    "    else: # mode == 'name'\n",
    "        # Get details by name only\n",
    "        # This should be used only when no other option is viable\n",
    "        \n",
    "        # Convert the name for query url\n",
    "        query_converted_name = urllib.parse.quote_plus(author_name)\n",
    "        \n",
    "        # x_concepts.id for 'Computer science' included in url\n",
    "        query_url = 'https://api.openalex.org/authors?search=' + query_converted_name \\\n",
    "                    + '&filter=x_concepts.id:C41008148&sort=relevance_score:desc'\n",
    "        result = get_api_result(query_url)\n",
    "        # print(query_url)\n",
    "\n",
    "        # If API gave error\n",
    "        if 'error' in result:\n",
    "            return result\n",
    "\n",
    "        # If no results\n",
    "        if len(result['results']) == 0:\n",
    "            return []\n",
    "\n",
    "        for candinate in result['results']:\n",
    "            # Check if the author is relevant to 'Computer Science'\n",
    "            for tag in candinate['x_concepts']:\n",
    "                if tag['display_name'] == 'Computer science':\n",
    "                    if tag['score'] > 70:\n",
    "                        author_info = candinate\n",
    "                        return author_info\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "        # If no possible candinate\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce4c78-8ff7-46ca-ab77-e8ac9d51bf1e",
   "metadata": {},
   "source": [
    "# 5. Add more info into original csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6e5da-5102-4760-9efb-259d616e4201",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.1. Load dataframe from Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc0f41c2-e56b-4391-8902-7b6cc8726298",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Email</th>\n",
       "      <th>dr_ntu_link</th>\n",
       "      <th>website_link</th>\n",
       "      <th>dblp_link</th>\n",
       "      <th>citations_all_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A S Madhukumar</td>\n",
       "      <td>asmadhukumar@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00083</td>\n",
       "      <td>['http://www3.ntu.edu.sg/home/asmadhukumar/', ...</td>\n",
       "      <td>https://dblp.org/pid/66/549</td>\n",
       "      <td>2907.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexei Sourin</td>\n",
       "      <td>assourin@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00274</td>\n",
       "      <td>['http://www3.ntu.edu.sg/home/assourin/', 'htt...</td>\n",
       "      <td>https://dblp.org/pid/15/3108</td>\n",
       "      <td>2939.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anupam Chattopadhyay</td>\n",
       "      <td>anupam@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp01076</td>\n",
       "      <td>['https://scholar.google.co.in/citations?user=...</td>\n",
       "      <td>https://dblp.org/pid/99/4535</td>\n",
       "      <td>6226.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anwitaman Datta</td>\n",
       "      <td>anwitaman@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00706</td>\n",
       "      <td>['https://personal.ntu.edu.sg/anwitaman/', 'ht...</td>\n",
       "      <td>https://dblp.org/pid/d/AnwitamanDatta</td>\n",
       "      <td>8047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arvind Easwaran</td>\n",
       "      <td>arvinde@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00687</td>\n",
       "      <td>['https://cps-research-group.github.io/', 'htt...</td>\n",
       "      <td>https://dblp.org/pid/73/1708</td>\n",
       "      <td>2817.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bo An</td>\n",
       "      <td>boan@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00698</td>\n",
       "      <td>['https://personal.ntu.edu.sg/boan/', 'https:/...</td>\n",
       "      <td>https://dblp.org/pid/42/6178-1</td>\n",
       "      <td>6957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cham Tat Jen</td>\n",
       "      <td>astjcham@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp01067</td>\n",
       "      <td>['https://personal.ntu.edu.sg/astjcham/index.h...</td>\n",
       "      <td>https://dblp.org/pid/29/3808</td>\n",
       "      <td>5533.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chan Syin</td>\n",
       "      <td>asschan@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00691</td>\n",
       "      <td>['http://www3.ntu.edu.sg/home/asschan/', 'http...</td>\n",
       "      <td>https://dblp.org/pid/80/2106</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chee Wei Tan</td>\n",
       "      <td>cheewei.tan@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp02029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chen Change Loy</td>\n",
       "      <td>ccloy@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00574</td>\n",
       "      <td>['https://personal.ntu.edu.sg/ccloy', 'https:/...</td>\n",
       "      <td>https://dblp.org/pid/01/5855</td>\n",
       "      <td>62816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chia Liang Tien</td>\n",
       "      <td>asltchia@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00991</td>\n",
       "      <td>['http://cemnet.ntu.edu.sg/home/asltchia/index...</td>\n",
       "      <td>https://dblp.org/pid/05/2952</td>\n",
       "      <td>5541.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chng Eng Siong</td>\n",
       "      <td>aseschng@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00098</td>\n",
       "      <td>['https://personal.ntu.edu.sg/aseschng/default...</td>\n",
       "      <td>https://dblp.org/pid/c/ChngEngSiong</td>\n",
       "      <td>7991.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cong Gao</td>\n",
       "      <td>gaocong@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00744</td>\n",
       "      <td>['https://personal.ntu.edu.sg/gaocong/', 'http...</td>\n",
       "      <td>https://dblp.org/pid/33/3180</td>\n",
       "      <td>17578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deepu Rajan</td>\n",
       "      <td>asdrajan@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp01157</td>\n",
       "      <td>['https://scholar.google.com/citations?user=1b...</td>\n",
       "      <td>https://dblp.org/pid/95/3115</td>\n",
       "      <td>4711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dmitrii Ustiugov</td>\n",
       "      <td>dmitrii.ustiugov@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp02117</td>\n",
       "      <td>['https://ustiugov.github.io', 'https://schola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Douglas Leslie Maskell</td>\n",
       "      <td>asdouglas@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp01059</td>\n",
       "      <td>['http://www3.ntu.edu.sg/home/asdouglas/']</td>\n",
       "      <td>https://dblp.org/pid/63/6663</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dusit Niyato</td>\n",
       "      <td>dniyato@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp01008</td>\n",
       "      <td>['http://www3.ntu.edu.sg/home/dniyato', 'https...</td>\n",
       "      <td>https://dblp.org/pid/76/440</td>\n",
       "      <td>66113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Erik Cambria</td>\n",
       "      <td>cambria@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00927</td>\n",
       "      <td>['https://sentic.net', 'https://orcid.org/0000...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Goh Wooi Boon</td>\n",
       "      <td>aswbgoh@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp00693</td>\n",
       "      <td>['https://scholar.google.com/citations?user=w7...</td>\n",
       "      <td>https://dblp.org/pid/97/6922</td>\n",
       "      <td>1436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Guan Cuntai</td>\n",
       "      <td>ctguan@ntu.edu.sg</td>\n",
       "      <td>https://dr.ntu.edu.sg/cris/rp/rp01023</td>\n",
       "      <td>['https://personal.ntu.edu.sg/ctguan', 'https:...</td>\n",
       "      <td>https://dblp.org/pid/95/7006</td>\n",
       "      <td>23747.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Name                        Email  \\\n",
       "0           A S Madhukumar      asmadhukumar@ntu.edu.sg   \n",
       "1            Alexei Sourin          assourin@ntu.edu.sg   \n",
       "2     Anupam Chattopadhyay            anupam@ntu.edu.sg   \n",
       "3          Anwitaman Datta         anwitaman@ntu.edu.sg   \n",
       "4          Arvind Easwaran           arvinde@ntu.edu.sg   \n",
       "5                    Bo An              boan@ntu.edu.sg   \n",
       "6             Cham Tat Jen          astjcham@ntu.edu.sg   \n",
       "7                Chan Syin           asschan@ntu.edu.sg   \n",
       "8             Chee Wei Tan       cheewei.tan@ntu.edu.sg   \n",
       "9          Chen Change Loy             ccloy@ntu.edu.sg   \n",
       "10         Chia Liang Tien          asltchia@ntu.edu.sg   \n",
       "11          Chng Eng Siong          aseschng@ntu.edu.sg   \n",
       "12                Cong Gao           gaocong@ntu.edu.sg   \n",
       "13             Deepu Rajan          asdrajan@ntu.edu.sg   \n",
       "14        Dmitrii Ustiugov  dmitrii.ustiugov@ntu.edu.sg   \n",
       "15  Douglas Leslie Maskell         asdouglas@ntu.edu.sg   \n",
       "16            Dusit Niyato           dniyato@ntu.edu.sg   \n",
       "17            Erik Cambria           cambria@ntu.edu.sg   \n",
       "18           Goh Wooi Boon           aswbgoh@ntu.edu.sg   \n",
       "19             Guan Cuntai            ctguan@ntu.edu.sg   \n",
       "\n",
       "                              dr_ntu_link  \\\n",
       "0   https://dr.ntu.edu.sg/cris/rp/rp00083   \n",
       "1   https://dr.ntu.edu.sg/cris/rp/rp00274   \n",
       "2   https://dr.ntu.edu.sg/cris/rp/rp01076   \n",
       "3   https://dr.ntu.edu.sg/cris/rp/rp00706   \n",
       "4   https://dr.ntu.edu.sg/cris/rp/rp00687   \n",
       "5   https://dr.ntu.edu.sg/cris/rp/rp00698   \n",
       "6   https://dr.ntu.edu.sg/cris/rp/rp01067   \n",
       "7   https://dr.ntu.edu.sg/cris/rp/rp00691   \n",
       "8   https://dr.ntu.edu.sg/cris/rp/rp02029   \n",
       "9   https://dr.ntu.edu.sg/cris/rp/rp00574   \n",
       "10  https://dr.ntu.edu.sg/cris/rp/rp00991   \n",
       "11  https://dr.ntu.edu.sg/cris/rp/rp00098   \n",
       "12  https://dr.ntu.edu.sg/cris/rp/rp00744   \n",
       "13  https://dr.ntu.edu.sg/cris/rp/rp01157   \n",
       "14  https://dr.ntu.edu.sg/cris/rp/rp02117   \n",
       "15  https://dr.ntu.edu.sg/cris/rp/rp01059   \n",
       "16  https://dr.ntu.edu.sg/cris/rp/rp01008   \n",
       "17  https://dr.ntu.edu.sg/cris/rp/rp00927   \n",
       "18  https://dr.ntu.edu.sg/cris/rp/rp00693   \n",
       "19  https://dr.ntu.edu.sg/cris/rp/rp01023   \n",
       "\n",
       "                                         website_link  \\\n",
       "0   ['http://www3.ntu.edu.sg/home/asmadhukumar/', ...   \n",
       "1   ['http://www3.ntu.edu.sg/home/assourin/', 'htt...   \n",
       "2   ['https://scholar.google.co.in/citations?user=...   \n",
       "3   ['https://personal.ntu.edu.sg/anwitaman/', 'ht...   \n",
       "4   ['https://cps-research-group.github.io/', 'htt...   \n",
       "5   ['https://personal.ntu.edu.sg/boan/', 'https:/...   \n",
       "6   ['https://personal.ntu.edu.sg/astjcham/index.h...   \n",
       "7   ['http://www3.ntu.edu.sg/home/asschan/', 'http...   \n",
       "8                                                 NaN   \n",
       "9   ['https://personal.ntu.edu.sg/ccloy', 'https:/...   \n",
       "10  ['http://cemnet.ntu.edu.sg/home/asltchia/index...   \n",
       "11  ['https://personal.ntu.edu.sg/aseschng/default...   \n",
       "12  ['https://personal.ntu.edu.sg/gaocong/', 'http...   \n",
       "13  ['https://scholar.google.com/citations?user=1b...   \n",
       "14  ['https://ustiugov.github.io', 'https://schola...   \n",
       "15         ['http://www3.ntu.edu.sg/home/asdouglas/']   \n",
       "16  ['http://www3.ntu.edu.sg/home/dniyato', 'https...   \n",
       "17  ['https://sentic.net', 'https://orcid.org/0000...   \n",
       "18  ['https://scholar.google.com/citations?user=w7...   \n",
       "19  ['https://personal.ntu.edu.sg/ctguan', 'https:...   \n",
       "\n",
       "                                dblp_link  citations_all_num  \n",
       "0             https://dblp.org/pid/66/549             2907.0  \n",
       "1            https://dblp.org/pid/15/3108             2939.0  \n",
       "2            https://dblp.org/pid/99/4535             6226.0  \n",
       "3   https://dblp.org/pid/d/AnwitamanDatta             8047.0  \n",
       "4            https://dblp.org/pid/73/1708             2817.0  \n",
       "5          https://dblp.org/pid/42/6178-1             6957.0  \n",
       "6            https://dblp.org/pid/29/3808             5533.0  \n",
       "7            https://dblp.org/pid/80/2106              266.0  \n",
       "8                                     NaN                NaN  \n",
       "9            https://dblp.org/pid/01/5855            62816.0  \n",
       "10           https://dblp.org/pid/05/2952             5541.0  \n",
       "11    https://dblp.org/pid/c/ChngEngSiong             7991.0  \n",
       "12           https://dblp.org/pid/33/3180            17578.0  \n",
       "13           https://dblp.org/pid/95/3115             4711.0  \n",
       "14                                    NaN              414.0  \n",
       "15           https://dblp.org/pid/63/6663                NaN  \n",
       "16            https://dblp.org/pid/76/440            66113.0  \n",
       "17                                    NaN            45997.0  \n",
       "18           https://dblp.org/pid/97/6922             1436.0  \n",
       "19           https://dblp.org/pid/95/7006            23747.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Submission/Takesawa_Saori.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b880d9f-6d92-4963-a021-da37ec5ff430",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.2. Get all ORCID IDs if possible from csv. Also delete ORCID link in website_link column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f12ba8a7-3ebb-47cd-b10b-93f3c7b9c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "orcid_link_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    found = 0\n",
    "    if isinstance(df['website_link'][i], str):\n",
    "        tmp_website_link = ast.literal_eval(df['website_link'][i])\n",
    "\n",
    "        for link in tmp_website_link:\n",
    "            if 'https://orcid.org/' in link:\n",
    "                found = 1\n",
    "                orcid_link_list.append(link)\n",
    "                break\n",
    "\n",
    "        # If no ORCID ID is found, add in as nan\n",
    "        if found == 0:\n",
    "            orcid_link_list.append(float('nan'))\n",
    "                \n",
    "    # If the website_link is nan \n",
    "    else:\n",
    "        orcid_link_list.append(float('nan'))\n",
    "\n",
    "df['orcid_link'] = orcid_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7fee2f50-f413-4ed5-9045-5ac07e7559d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_link_list = list(df['website_link'])\n",
    "\n",
    "# Remove ORCID link in website_link if have, to clean up csv\n",
    "for i in range(len(website_link_list)):\n",
    "    if isinstance(df['website_link'][i], str):\n",
    "        website_link_list[i] = [link for link in ast.literal_eval(website_link_list[i]) if 'https://orcid.org' not in link]\n",
    "\n",
    "df['website_link'] = website_link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a153d-aab1-4ad3-9ccb-244331a9699d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.3. Get all Google Scholar link if possible from csv. Also delete Google Scholar link in website_link column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8bbbd6b8-41e2-4691-95b4-adc9394ed99e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "google_scholar_link_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    found = 0\n",
    "    if isinstance(df['website_link'][i], list):\n",
    "        tmp_website_link = df['website_link'][i]\n",
    "\n",
    "        for link in tmp_website_link:\n",
    "            if 'https://scholar.google.com' in link:\n",
    "                found = 1\n",
    "                google_scholar_link_list.append(link)\n",
    "                break\n",
    "\n",
    "        # If no ORCID ID is found, add in as nan\n",
    "        if found == 0:\n",
    "            google_scholar_link_list.append(float('nan'))\n",
    "                \n",
    "    # If the website_link is nan \n",
    "    else:\n",
    "        google_scholar_link_list.append(float('nan'))\n",
    "\n",
    "df['google_scholar_link'] = google_scholar_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1cac3d6b-29ea-4406-b244-59622fb0e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_link_list = list(df['website_link'])\n",
    "\n",
    "# Remove ORCID link in website_link if have, to clean up csv\n",
    "for i in range(len(website_link_list)):\n",
    "    if isinstance(df['website_link'][i], list):\n",
    "        website_link_list[i] = [link for link in website_link_list[i] if 'https://scholar.google' not in link]\n",
    "\n",
    "df['website_link'] = website_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8dff4dfd-1eba-459b-a201-7f53414a2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('Takesawa_Saori_updated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af5f387-5b73-4945-a39f-9ee8380cd8c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.4. Retrieve missing ORCID id for each faculty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21885321-68c7-43af-9cdb-deaba62d7794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3520a25f61444a7296229034811706c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add ORCID link into the df\n",
    "# For that, first retrieve the doi if available from the faculties' DR-NTU page\n",
    "\n",
    "# Get the list of orcid links\n",
    "orcid_link_list = list(df['orcid_link'])\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "\n",
    "    orcid_link = None\n",
    "\n",
    "    if isinstance(orcid_link_list[i], str):\n",
    "        continue\n",
    "\n",
    "    # Retrieve the doi\n",
    "    doi_list = get_doi_list_from_drNTU(df['dr_ntu_link'][i])\n",
    "\n",
    "    # If DOI obtained, use that to search for the faculty in the API\n",
    "    for doi in doi_list:\n",
    "        author_details = get_author_info_from_OpenAlexAPI(df['Name'][i], doi, 'doi')\n",
    "        \n",
    "        # If API gave error, go to next DOI\n",
    "        if 'error' in author_details:\n",
    "            continue\n",
    "            \n",
    "        author_details_found = 1\n",
    "\n",
    "        # If author has ORCID id and not appended to df, add to df\n",
    "        if author_details['author']['orcid'] and not isinstance(orcid_link_list[i], str):\n",
    "            orcid_link = author_details['author']['orcid']\n",
    "        break\n",
    "\n",
    "    # If cannot retrieve any DOI or still have not found author, use publication title to search\n",
    "    if author_details_found == 0:\n",
    "        pub_list = get_pub_list_from_article(df['dr_ntu_link'][i])\n",
    "\n",
    "        for pub in pub_list:\n",
    "            author_details = get_author_info_from_OpenAlexAPI(df['Name'][i], pub, 'pub')\n",
    "\n",
    "            # If API gave error or no results, go to next pub\n",
    "            if 'error' in author_details or len(author_details)==0:\n",
    "                continue\n",
    "            author_details_found = 1\n",
    "\n",
    "\n",
    "            # If author has ORCID id and not appended to df, add to df\n",
    "            if author_details['author']['orcid'] and not isinstance(orcid_link_list[i], str):\n",
    "                orcid_link = author_details['author']['orcid']\n",
    "            break\n",
    "    \n",
    "    # If still have not found author, use name and institution to search\n",
    "    if author_details_found == 0:\n",
    "        author_details = get_author_info_from_OpenAlexAPI(df['Name'][i], '', 'institution')\n",
    "    \n",
    "        # If API did not give error and have results\n",
    "        if not ('error' in author_details or len(author_details)==0):\n",
    "            author_details_found = 1\n",
    "            \n",
    "            # If author has ORCID id, add to df\n",
    "            if author_details['orcid']:\n",
    "                orcid_link = author_details['orcid']\n",
    "\n",
    "    # If still have not found author, use name only to search\n",
    "    if author_details_found == 0:\n",
    "        author_details = get_author_info_from_OpenAlexAPI(df['Name'][i], '', 'name')\n",
    "    \n",
    "        # If API did not give error and have results\n",
    "        if not ('error' in author_details or len(author_details)==0):\n",
    "            author_details_found = 1\n",
    "            \n",
    "            # If author has ORCID id, add to df\n",
    "            if author_details['orcid']:\n",
    "                orcid_link = author_details['orcid'] \n",
    "\n",
    "    if author_details_found == 1:\n",
    "        if orcid_link:\n",
    "            orcid_link_list[i] = orcid_link\n",
    "        \n",
    "\n",
    "df['orcid_link'] = orcid_link_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89317ce-395c-4502-9cf7-379f5099e645",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.5. Get all interest for each faculty from DR_NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc8b9d-8529-4d52-8561-a3033080cf70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get interest from DR-NTU profile page\n",
    "interest_list = []\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    interest_list.append(get_research_interest_from_drNTU(df['dr_ntu_link'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adacac7e-4def-4c0b-91d7-5768ea22b724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Interests'] = interest_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890d54af-2f5b-46af-bf12-c4babf278e44",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5.6. Get profile image of each faculty from DR-NTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "882cfc2d-391b-4597-bafa-3f59f681378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0813c0e47694534aae509c81edaa96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_link_list = []\n",
    "\n",
    "for i in tqdm( range(len(df)) ):\n",
    "    drNTU_link = df['dr_ntu_link'][i]\n",
    "    soup_source = requests.get(drNTU_link).text\n",
    "    soup = BeautifulSoup(soup_source,'lxml')\n",
    "\n",
    "    # Extract the profile image link \n",
    "    # also, replace the single space in 'src' to '%20' to convert to proper url format\n",
    "    img_link = 'https://dr.ntu.edu.sg' + soup.find('img', id=\"picture\")['src'].replace(' ', '%20')\n",
    "\n",
    "    img_link_list.append(img_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4414a54-1c26-4aa5-a92f-ebec142a0ad3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['img_link'] = img_link_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcd58d6b-6da0-41ee-94b2-1bdc6879844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Takesawa_Saori_updated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (pytorch_env)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
